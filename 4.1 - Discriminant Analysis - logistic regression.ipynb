{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Logistic Regression\n",
    "\n",
    "---\n",
    "> Erick Eduardo Aguilar HernÃ¡ndez:\n",
    "> * mat.ErickAguilar@ciencias.unam.mx\n",
    "> * isc.ErickAguilar@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "___\n",
    "\n",
    "Since the indicator variable follows a Bernoulli distribution the Likehood function asociated to $p(\\mathbf{x})$ for the data matrix $\\mathbf{X} \\in M_{n \\times p+1}(\\mathbb{R})$, where each row are indepent observation without being identically distributed in general:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) = \\prod_{i=1}^{n} p(\\mathbf{x}_i)^{y_i}(p(\\mathbf{x}_i))^{1-y_i}\n",
    "$$\n",
    "\n",
    "The logarithm of the Likehood function is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) &= \\sum_{i=1}^{n} y_i ln \\left(p(\\mathbf{x}_i)\\right)+\\sum_{i=1}^{n} (1-y_i)ln \\left(1-p(\\mathbf{x}_i)\\right) \\\\\n",
    "& = \\sum_{i=1}^{n} y_i ln \\left(p(\\mathbf{x}_i)\\right)-\\sum_{i=1}^{n} y_i ln \\left(1-\n",
    "p(\\mathbf{x}_i)\\right)+\\sum_{i=1}^{n} ln \\left(1-p(\\mathbf{x}_i)\\right) \\\\\n",
    "& = \\sum_{i=1}^{n} y_i \\left[ ln \\left(p(\\mathbf{x}_i)\\right)- ln \\left(1-p(\\mathbf{x}_i)\\right)\\right]+\\sum_{i=1}^{n} ln \\left(1-\\frac{1}{1+e^{-\\mathbf{x_i' \\beta}}}\\right) \\\\\n",
    "& = \\sum_{i=1}^{n} y_i ln\\left(\\frac{p(\\mathbf{x_i})}{1-p(\\mathbf{x_i})}\\right) +\\sum_{i=1}^{n} ln \\left(\\frac{e^{--\\mathbf{x_i' \\beta}}}{1+e^{-\\mathbf{x_i' \\beta}}}\\right)\\\\\n",
    "ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) &= \\sum_{i=1}^{n} y_i \\left[\\beta_0+\\mathbf{x_i' \\beta}\\right] +\\sum_{i=1}^{n} ln \\left(\\frac{1}{1+e^{-\\mathbf{x_i' \\beta}}}\\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Computing the partials to obtain the logistic normal equations:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p)}{\\partial \\beta_0} &= \\sum_{i=1}^{n} y_i-\\sum_{i=1}^{n}\\frac{e^{\\beta_0+\\mathbf{x_i' \\beta}}}{1+e^{\\beta_0+\\mathbf{x_i' \\beta}}} = \\sum_{i=1}^{n} (y_i-p(\\mathbf{x_i})) = 0\\\\\n",
    "\\frac{\\partial ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p)}{\\partial \\beta_j} &= \\sum_{i=1}^{n} x_{ij} y_i-\\sum_{i=1}^{n}x_{ij}\\frac{e^{\\beta_0+\\mathbf{x_i' \\beta}}}{1+e^{\\beta_0+\\mathbf{x_i' \\beta}}} = \\sum_{i=1}^{n} x_{ij} (y_i-p(\\mathbf{x_i})) = 0 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "That equations are transcendental so they could not be solved in terms of elemental functions. This maximum likehood estimator should be computing using descent gradient.\n",
    "\n",
    "### Wald test for goodness of fit\n",
    "___\n",
    "Consider the MLE $\\hat{\\beta_j}$, by the asymptotic distribution theorem for the MLE, whe have that:\n",
    "\n",
    "$$\n",
    "\\frac{\\hat{\\beta_j}-B_0}{\\sqrt{V(\\hat{\\beta_j}})} \\sim N(0,1)\n",
    "\\implies \\frac{(\\hat{\\beta_j}-B_0)^2}{V(\\hat{\\beta_j})} \\sim \\chi_{(1)}^2\n",
    "$$\n",
    "\n",
    "Where $B_0$ is a fixed expected value to contrast, usually $B_0 = 0$ to test significance. Its possible to obtain the variance of the MLE vector $(\\hat{\\beta}_0,\\hat{\\beta}_1,...,\\hat{\\beta}_p)$ computing the Fisher information. $\\mathbf{I(\\beta)}=-E\\left[ \\nabla^2 ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) \\right]$, computing the partial derivates of second order:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial^2}{\\partial \\beta_j \\partial \\beta_k} \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) &= -\\sum_{i=1}^n x_{ij}x_{ik} \\frac{e^{\\sum_{l=0}^{p} \\beta_l x_{il}}}{\\left(1+e^{\\sum_{l=0}^{p} \\beta_l x_{il}}\\right)^2} = -\\sum_{i=1}^n x_{ij}x_{ik} p(\\mathbf{x_i})(1-p(\\mathbf{x_i}))\\\\\n",
    "\\nabla^2 ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) &= \n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & \\dots & 1 \\\\\n",
    "    x_{11} & x_{21} & \\dots & x_{1n} \\\\\n",
    "    \\vdots & \\vdots & \\ddots  & \\vdots\\\\\n",
    "    x_{1p} & x_{2p} & \\dots & x_{pn}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    p(\\mathbf{x_1})(1-p(\\mathbf{x_1})) & 0 & \\dots  & 0 \\\\\n",
    "    0 & p(\\mathbf{x_2})(1-p(\\mathbf{x_2})) & \\dots & 0 \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots  \\\\\n",
    "    0 & 0  & \\dots  & p(\\mathbf{x_n})(1-p(\\mathbf{x_n})) \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    1 & x_{11} & \\dots & x_{1p} \\\\\n",
    "    1 & x_{21} & \\dots & x_{2p} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    1 & x_{n1} & \\dots & x_{np}\n",
    "\\end{bmatrix}\\\\\n",
    "\\nabla^2 ln \\mathcal{L}(\\beta_0,\\beta_1,...,\\beta_p) &= \\mathbf{X'}diag\\left(p(\\mathbf{x_1})(1-p(\\mathbf{x_1})),\\dots,p(\\mathbf{x_n})(1-p(\\mathbf{x_n}))\\right)\\mathbf{X'}\\\\\n",
    "\\mathbf{Cov(\\beta)} & = \\left[\\mathbf{X'}diag\\left(p(\\mathbf{x_1})(1-p(\\mathbf{x_1})),\\dots,p(\\mathbf{x_n})(1-p(\\mathbf{x_n}))\\right)\\mathbf{X'}\\right]^{-1} \\\\\n",
    "\\implies V(\\hat{\\beta_j}) &= \\left[\\mathbf{X'}diag\\left(p(\\mathbf{x_1})(1-p(\\mathbf{x_1})),\\dots,p(\\mathbf{x_n})(1-p(\\mathbf{x_n}))\\right)\\mathbf{X'}\\right]^{-1}_{jj}\\\\ \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Considere the follwing hypotesis testing for the vector of MLE betas $\\mathbf{\\hat{\\beta}}=(\\hat{\\beta_0},...,\\hat{\\beta_p})$, with alternative hypotesis $H_a: \\mathbf{\\hat{\\beta}=0}$ versus $H_a: \\mathbf{\\hat{\\beta} \\neq 0}$ to contrast the significance of the coeficients. The statistic:\n",
    "\n",
    "$$\\chi^2 = \\sum_{j=0}^{p} \\frac{\\beta_j^2}{V(\\hat{\\beta_j})} \\sim \\chi_{(p)}^2$$\n",
    "\n",
    "For some confidence $(1-\\alpha)100$% and the chisquared critical value asociated $\\chi_{(1-\\alpha)}^2$ dont reject when $\\chi^2 \\leq \\chi_{(1-\\alpha)}^2$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

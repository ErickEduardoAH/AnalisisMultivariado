{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Factor analysis\n",
    "\n",
    "---\n",
    "> Erick Eduardo Aguilar HernÃ¡ndez:\n",
    "> * mat.ErickAguilar@gmail.com.mx\n",
    "> * isc.ErickAguilar@gmail.com\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some timed is not possible to measure directly the concepts of primary interest however it is possible to observe its effect on observable variables. Factor analysis is a multivariate technique applied to a set of observed variables that seeks to find underlying factors (subsets of variables) from which the observed variables were generated. Factor analysis is carried out on the correlation matrix of the observed variables. A factor is a weighted average of\n",
    "the original variables. The factor analyst hopes to find a few factors from which the original correlation matrix\n",
    "may be generated.\n",
    "\n",
    "The basis of factor analysis is a regression model linking the manifest variables to a set of unobserved (and unobservable) latent variables. In essence the model assumes that the observed relationships between the manifest variables (as measured by their covariances or correlations) are a result of the relationships of these variables to the latent variables. (Since it is the covariances or correlations of the manifest variables that are central to factor analysis, we can, **in the description of the mathematics of the method given below, assume that the manifest variables all have zero mean**.\n",
    "\n",
    "Lets the **observable random vector** $\\mathbf{x} \\in \\mathbb{R^p}$ the factor model postulates that $\\mathbf{x}$ is linearly dependent upon a few unobervable random variables $F_1,\\dots,F_m$ called common factors, and p adition sources of deviation $\\varepsilon_1,\\dots,\\varepsilon_p$ called specific factors, this specific factors is asociated with only one , this model can be expressed as equation system.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_1 &= \\ell_{11} F_1 + \\ell_{12} F_2 +\\dots + \\ell_{1m} F_m+\\varepsilon_1\\\\\n",
    "\\vdots &= \\vdots \\\\\n",
    "X_p &= \\ell_{p1} F_1 + \\ell_{p2} F_2 +\\dots + \\ell_{pm} F_m+\\varepsilon_p\\\\\n",
    "\\\\\n",
    "\\left[ \\begin{array}{ccccc}\n",
    "X_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "X_{p} \\end{array} \\right]\n",
    "& = \n",
    "\\left[ \\begin{array}{ccccc}\n",
    "\\ell_{1 1} & \\cdots & \\ell_{1 m} \\\\\n",
    "\\vdots  & \\ddots & \\vdots \\\\\n",
    "\\ell_{p 1} & \\cdots & \\ell_{p m} \\end{array} \\right]\n",
    "\\left[ \\begin{array}{ccccc}\n",
    "F_{1} \\\\\n",
    "\\vdots \\\\\n",
    "F_{p} \\end{array} \\right]\n",
    "+\n",
    "\\left[ \\begin{array}{ccccc}\n",
    "\\varepsilon_{1} \\\\\n",
    "\\vdots  \\\\\n",
    "\\varepsilon_{p} \\end{array} \\right]\\\\\n",
    "\\\\\n",
    "\\textbf{x} & =\\textbf{LF}+\\mathbf{\\epsilon}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The coeficient matrix $\\mathbf{L}$ is called matrix of factor loadings, some assumptions for the model are as follows:\n",
    " * $E[\\mathbf{F}]=0$\n",
    " * $E[\\mathbf{\\epsilon}]=0$\n",
    " * $Cov[\\mathbf{\\epsilon}]=E[\\mathbf{\\epsilon \\epsilon'}]=\\mathbf{\\Psi}=diag(\\Psi_1,\\dots,\\Psi_p)$\n",
    " * Ortogonality in factors: $Cov[\\mathbf{F}]=E[\\mathbf{FF'}]=\\mathbf{I_m}$\n",
    " * $\\mathbf{F}$ and $\\mathbf{\\epsilon}$ are independent: $Cov[\\mathbf{\\epsilon,F}]=E[\\mathbf{\\epsilon F'}]=0$\n",
    "\n",
    "Examining implications of model assumptions:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "V[Y_i] &= \\ell_{i1}^2 V[F_1 ]+ \\ell_{i2}^2 V[F_2] +\\dots + \\ell_{im}^2 V[F_m]+V[\\varepsilon_i]\\\\\n",
    "&=\\underset{communalities}{\\underbrace{\\ell_{11}^2+\\ell_{12}^2+\\dots+\\ell_{1m}^2}}+\\underset{specic variance}{\\underbrace{\\sigma^2}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This model is knowed as ortogonal factor model, and implies covariance structure for $\\mathbf{x}$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{\\Sigma}&= E[\\mathbf{xx'}] \\\\\n",
    "&= E[(\\textbf{LF}+\\mathbf{\\epsilon})(\\textbf{LF}+\\mathbf{\\epsilon})']\\\\\n",
    "&= E[(\\textbf{LF}+\\mathbf{\\epsilon})((\\textbf{LF})'+\\mathbf{\\epsilon}')]\\\\\n",
    "&= E[\\textbf{LF}(\\textbf{LF})'+\\mathbf{\\epsilon}(\\textbf{LF})'+\\textbf{LF}\\mathbf{\\epsilon}'+\\mathbf{\\epsilon}\\mathbf{\\epsilon}']\\\\\n",
    "&= E[\\textbf{LF}(\\textbf{LF})']+E[\\mathbf{\\epsilon}(\\textbf{LF})']+E[\\textbf{LF}\\mathbf{\\epsilon}']+E[\\mathbf{\\epsilon}\\mathbf{\\epsilon}']\\\\\n",
    "&= E[\\textbf{LFF'L}]+E[\\mathbf{\\epsilon F'L'}]+E[\\textbf{LF}\\mathbf{\\epsilon}']+E[\\mathbf{\\epsilon}\\mathbf{\\epsilon}']\\\\\n",
    "&= \\textbf{L}E[\\textbf{FF'}]\\textbf{L'}+E[\\mathbf{\\epsilon F'}]\\textbf{L'}+\\textbf{L'}E[\\textbf{F}\\mathbf{\\epsilon}']+E[\\mathbf{\\epsilon}\\mathbf{\\epsilon}']\\\\\n",
    "\\mathbf{\\Sigma}&= \\textbf{LL'}+\\mathbf{\\Psi}\\\\\n",
    "\\implies \\mathbf{\\Psi}&=\\textbf{LL'}-\\mathbf{\\Sigma}&\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### The principal compent method\n",
    "___\n",
    "\n",
    "From the scpetral descomposition of $\\mathbf{\\Sigma}$ it's possible aproximate $\\mathbf{LL'}$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Sigma&=\\left[\\sum_{k=1}^p\\lambda_k\\mathbf{\\gamma_k'\\gamma_k}\\right]\\\\\n",
    "&\\simeq\\left[\\sum_{k=1}^m\\lambda_k\\mathbf{\\gamma_k'\\gamma_k}\\right]\\\\\n",
    "&=\\left[\\sqrt{\\lambda_1} \\mathbf{\\gamma_1} \\dots \\sqrt{\\lambda_1} \\mathbf{\\gamma_p} \\right]\n",
    "\\left[ \\begin{array}{ccccc}\n",
    "\\sqrt{\\lambda_1} \\mathbf{\\gamma_1} \\\\\n",
    "\\vdots  \\\\\n",
    "\\sqrt{\\lambda_1} \\mathbf{\\gamma_p}\\end{array} \\right]\\\\\n",
    "&=\\mathbf{L L'}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This in turn suggests that the specific variances, which are the diagonal elements of this matrix $\\mathbf{\\Psi}$, can be estimated using this expression:\n",
    "\n",
    "$$\n",
    "\\psi_i = \\sigma_i^2 - \\sum_{k=1}^{m} \\lambda_k \\gamma_{ki}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt \n",
    "from pyspark import SparkContext\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.sql import Column as c\n",
    "from pyspark.sql.functions import array, udf, lit, col as c\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "pd.set_option('max_colwidth',100)\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sc = SparkContext('local[*]')\n",
    "except:\n",
    "    sc = SparkContext.getOrCreate('local[*]')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Climate</th>\n",
       "      <th>HousingCost</th>\n",
       "      <th>HlthCare</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Transp</th>\n",
       "      <th>Educ</th>\n",
       "      <th>Arts</th>\n",
       "      <th>Recreat</th>\n",
       "      <th>Econ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>521</td>\n",
       "      <td>6200</td>\n",
       "      <td>237</td>\n",
       "      <td>923</td>\n",
       "      <td>4031</td>\n",
       "      <td>2757</td>\n",
       "      <td>996</td>\n",
       "      <td>1405</td>\n",
       "      <td>7633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akron</td>\n",
       "      <td>575</td>\n",
       "      <td>8138</td>\n",
       "      <td>1656</td>\n",
       "      <td>886</td>\n",
       "      <td>4883</td>\n",
       "      <td>2438</td>\n",
       "      <td>5564</td>\n",
       "      <td>2632</td>\n",
       "      <td>4350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albany</td>\n",
       "      <td>468</td>\n",
       "      <td>7339</td>\n",
       "      <td>618</td>\n",
       "      <td>970</td>\n",
       "      <td>2531</td>\n",
       "      <td>2560</td>\n",
       "      <td>237</td>\n",
       "      <td>859</td>\n",
       "      <td>5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albany-Schenectady-Troy</td>\n",
       "      <td>476</td>\n",
       "      <td>7908</td>\n",
       "      <td>1431</td>\n",
       "      <td>610</td>\n",
       "      <td>6883</td>\n",
       "      <td>3399</td>\n",
       "      <td>4655</td>\n",
       "      <td>1617</td>\n",
       "      <td>5864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>659</td>\n",
       "      <td>8393</td>\n",
       "      <td>1853</td>\n",
       "      <td>1483</td>\n",
       "      <td>6558</td>\n",
       "      <td>3026</td>\n",
       "      <td>4496</td>\n",
       "      <td>2612</td>\n",
       "      <td>5727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      City  Climate  HousingCost  HlthCare  Crime  Transp  \\\n",
       "0                  Abilene      521         6200       237    923    4031   \n",
       "1                    Akron      575         8138      1656    886    4883   \n",
       "2                   Albany      468         7339       618    970    2531   \n",
       "3  Albany-Schenectady-Troy      476         7908      1431    610    6883   \n",
       "4              Albuquerque      659         8393      1853   1483    6558   \n",
       "\n",
       "   Educ  Arts  Recreat  Econ  \n",
       "0  2757   996     1405  7633  \n",
       "1  2438  5564     2632  4350  \n",
       "2  2560   237      859  5250  \n",
       "3  3399  4655     1617  5864  \n",
       "4  3026  4496     2612  5727  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = ['City','Climate','HousingCost','HlthCare','Crime','Transp',\\\n",
    "          'Educ','Arts','Recreat','Econ']\n",
    "ratedPlacesDatasetPath = 'DataSets/RatedPlaces.txt'\n",
    "placesRatedDF = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "                          .options(header='true',inferschema='true')\\\n",
    "                          .load(ratedPlacesDatasetPath).select(schema)\n",
    "placesRatedRDD = placesRatedDF.rdd.map(lambda x: ([mt.log10(y) for y in x[1:p+1]],x[0]))\n",
    "placesRatedDF.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.03507174,  0.00890081, -0.14747075],\n",
       "        [-0.09335123,  0.0093354 , -0.13421161],\n",
       "        [-0.40777195, -0.8576495 , -0.27873303],\n",
       "        [-0.10045602,  0.22245397, -0.58634056],\n",
       "        [-0.15010322,  0.06022323, -0.21418603],\n",
       "        [-0.03215112, -0.06078162, -0.01074782],\n",
       "        [-0.87433351,  0.30267364,  0.36434266],\n",
       "        [-0.15900414,  0.33566365, -0.58762659],\n",
       "        [-0.01949541,  0.05641391, -0.12128687]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "p=len(schema)-1\n",
    "k=3\n",
    "labeledVectorsDF = placesRatedRDD.map(lambda x:(Vectors.dense(x[0]),x[1]))\\\n",
    "                                 .toDF(['features','label'])\n",
    "pcaModel = PCA(k=k, inputCol=\"features\", outputCol=\"transformationPCA\").fit(labeledVectorsDF)\n",
    "np.matrix(pcaModel.pc.toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.7168377232995247,\n",
       "  3.792391689498254,\n",
       "  2.374748346010104,\n",
       "  2.965201701025912,\n",
       "  3.605412798153051,\n",
       "  3.4404367661057735,\n",
       "  2.998259338423699,\n",
       "  3.1476763242410986,\n",
       "  3.882695262381597,\n",
       "  -5.565001706727944,\n",
       "  0.8736115913272944,\n",
       "  -5.347566671995009]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranformedRatingsRDD = pcaModel.transform(labeledVectorsDF)\\\n",
    "                               .select(['features','transformationPCA'])\\\n",
    "                               .rdd.map(lambda r: list(r[0])+list(r[1]))\\\n",
    "                               .map(lambda r: ([float(y) for y in r]))\n",
    "tranformedRatingsRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "correlation = Statistics.corr(x=tranformedRatingsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pc1</th>\n",
       "      <td>-0.189789</td>\n",
       "      <td>-0.543985</td>\n",
       "      <td>-0.781953</td>\n",
       "      <td>-0.366013</td>\n",
       "      <td>-0.585943</td>\n",
       "      <td>-0.394110</td>\n",
       "      <td>-0.985525</td>\n",
       "      <td>-0.520607</td>\n",
       "      <td>-0.141805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc2</th>\n",
       "      <td>0.017712</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>-0.604773</td>\n",
       "      <td>0.298044</td>\n",
       "      <td>0.086447</td>\n",
       "      <td>-0.273976</td>\n",
       "      <td>0.125454</td>\n",
       "      <td>0.404134</td>\n",
       "      <td>0.150892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc3</th>\n",
       "      <td>-0.215339</td>\n",
       "      <td>-0.211038</td>\n",
       "      <td>-0.144230</td>\n",
       "      <td>-0.576466</td>\n",
       "      <td>-0.225611</td>\n",
       "      <td>-0.035550</td>\n",
       "      <td>0.110816</td>\n",
       "      <td>-0.519166</td>\n",
       "      <td>-0.238055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "pc1 -0.189789 -0.543985 -0.781953 -0.366013 -0.585943 -0.394110 -0.985525   \n",
       "pc2  0.017712  0.020004 -0.604773  0.298044  0.086447 -0.273976  0.125454   \n",
       "pc3 -0.215339 -0.211038 -0.144230 -0.576466 -0.225611 -0.035550  0.110816   \n",
       "\n",
       "            7         8  \n",
       "pc1 -0.520607 -0.141805  \n",
       "pc2  0.404134  0.150892  \n",
       "pc3 -0.519166 -0.238055  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=correlation[p:,:p],index=['pc1','pc2','pc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

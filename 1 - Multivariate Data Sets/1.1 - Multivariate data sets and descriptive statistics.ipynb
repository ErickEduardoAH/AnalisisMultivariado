{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Data Sets\n",
    "\n",
    "---\n",
    "> Erick Eduardo Aguilar Hernández:\n",
    "> * mat.ErickAguilar@gmail.com.mx\n",
    "> * isc.ErickAguilar@gmail.com\n",
    "\n",
    "---\n",
    "Multivariate analysis is the branch of statistics that generalizes methods of inferential statistics, so that a population $X$ can be characterized through a finite collection of random variables $X_i$. i.e multivariated distribution of random vectors. E.j. a species of animals can be characterized through quantitative and qualitative variables as they are high body, body width, weight, head high, head width, leg size, hair color, eye color, sex, etc. this variables are called explicatives.\n",
    "\n",
    "$$ \\vec{X} = (X_1,X_2,...,X_p) $$\n",
    "\n",
    "As in classical inferential statistics, multivariate analysis the main idea is to generalize patterns or obtain useful conclusions from a multivariate population based on the information of the sample however in this case the information is multidimensional.\n",
    "\n",
    "#### Statistical learning and machine learning\n",
    "\n",
    "There are often situations in which it is necessary to make inferences about the future behavior of one or several variables in terms of random vectors, infer the population type of a random vector since there are several populations that share the same explicative variables but with different distribution, or find boundaries and structures of clustering since there are different types of mixed populations of which the membership of the vectors is not known. \n",
    "\n",
    "For these situations and some more, exist results based on multivariate analysis that provides methods for a non-exactly teoric solution to the problem, this is called **statistical learning**. In addition to this, a computational approach is added considering algorithms, complexity, expenditure, data structures, etc. then the set of these techniques known as **machine learning**.\n",
    "\n",
    "\n",
    "#### Data matrix\n",
    "\n",
    "Supose that you have n obervations of the random vector $\\vec{X}$ (the distribution of the population), such that each vector have p explicative variables. Then set of observations $\\{\\vec{X}_i\\}_{i=1}^n=\\{(X_1,...,X_p)_i\\}_{i=1}^n$ can be represented as a matrix called data matrix $\\textbf{X}_{n \\times p}$, the rows of this matrix represent de index of the observation and each column represent one of the explicative variables.\n",
    "\n",
    "$$\\textbf{X}_{n \\times p}=\n",
    "\\left( \\begin{array}{ccccc}\n",
    "x_{1 1} & \\cdots & x_{1 j} & \\cdots & x_{1 p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "x_{i 1} & \\cdots & x_{i j} & \\cdots & x_{i p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "x_{n 1} & \\cdots & x_{n j} & \\cdots & x_{n p} \\end{array} \\right)\n",
    "$$\n",
    "\n",
    "**Notation:**\n",
    "* $\\textbf{x}_i$ Indicates the i-th row of $\\textbf{X}$, however it will operated as a column.\n",
    "* $X_j$ Indicates the j-th column of $\\textbf{X}$\n",
    "\n",
    "**Example 1.1 - 1 [Iris plants]**: The following datset contains samples of 3 iris plants populations of 50, obervations each one. The 3 populations that share the same explicative variables:\n",
    "1. Sepal length in cm\n",
    "2. Sepal width in cm\n",
    "3. Petal length in cm\n",
    "4. Petal width in cm\n",
    "5. Species: \n",
    "      - Iris Setosa\n",
    "      - Iris Versicolour\n",
    "      - Iris Virginica\n",
    "\n",
    "URL of the dataset.\n",
    "https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Column as C\n",
    "\n",
    "try:\n",
    "    sc = SparkContext('local[*]')\n",
    "except:\n",
    "    sc = SparkContext.getOrCreate('local[*]')\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "0             5.1           3.5            1.4           0.2      Iris-setosa\n",
       "1             4.9           3.0            1.4           0.2      Iris-setosa\n",
       "2             4.7           3.2            1.3           0.2      Iris-setosa\n",
       "3             4.6           3.1            1.5           0.2      Iris-setosa\n",
       "4             7.0           3.2            4.7           1.4  Iris-versicolor\n",
       "5             6.4           3.2            4.5           1.5  Iris-versicolor\n",
       "6             6.9           3.1            4.9           1.5  Iris-versicolor\n",
       "7             5.5           2.3            4.0           1.3  Iris-versicolor\n",
       "8             6.3           3.3            6.0           2.5   Iris-virginica\n",
       "9             5.8           2.7            5.1           1.9   Iris-virginica\n",
       "10            7.1           3.0            5.9           2.1   Iris-virginica\n",
       "11            6.3           2.9            5.6           1.8   Iris-virginica"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisPath = '../DataSets/Iris.csv'\n",
    "lim = 4\n",
    "irisDF = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "                   .options(header='true',inferschema='true')\\\n",
    "                   .load(irisPath)\n",
    "irisSetosaDF = irisDF.where(irisDF.Species == 'Iris-setosa')\n",
    "irisVersicolorDF = irisDF.where(irisDF.Species == 'Iris-versicolor')\n",
    "irisVirginicaDF = irisDF.where(irisDF.Species == 'Iris-virginica')\n",
    "irisSetosaDF.limit(lim).union(irisVersicolorDF.limit(lim)).union(irisVirginicaDF.limit(lim)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Multivariate Data\n",
    "\n",
    "**Scatter plots matrix**: A scatter plot matrix arranges all possible two-way scatter plots in a p × p matrix. These displays can be enhanced with brushing, in which individual points or groups of points can be selected in one plot, and be simultaneously highlighted in the other plots.\n",
    "\n",
    "**Example 1.1 - 2 [Scatter plot matrix of iris plants]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "smp = sns.pairplot(irisDF.toPandas(),hue=\"Species\",diag_kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate descriptive statistics\n",
    "---\n",
    "\n",
    "#### Mean vector\n",
    "\n",
    "For the j-th column of the data matrix, the sample mean of the values $\\{x_{1j},...,x_{nj}\\}$ is given by $\\bar{x_j}=\\frac{1}{n}\\sum_{i=1}^{n}x_{ij}$. If we assume that the sample is independent and identically distributed then the expected value $E[X_j]=\\mu_j=E[\\bar{x_j}]$ because $\\bar{x_j}$ it's the unviased estimator of $\\mu_j$. On the other hand we know of the multivariate distributions that if you have a random vector $\\vec{X}$ of dimension p, then its expected value is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\vec{\\mu} = E[\\vec{X}] & = (E[X_1],\\dotsc,E[X_j],\\dotsc,E[X_p]) \\\\\n",
    "& = (E[\\bar{x_1}],\\dotsc,E[\\bar{x_j}],\\dotsc,E[\\bar{x_j}]) \\\\\n",
    "& = E[(\\bar{x_1},\\dots,\\bar{x_j},\\dotsc,\\bar{x_p})]\\\\\n",
    "& = E\\left[\\left(\\frac{1}{n}\\sum_{i=1}^{n}x_{i1},\\dots,\\frac{1}{n}\\sum_{i=1}^{n}x_{ij},\\dotsc,\\frac{1}{n}\\sum_{i=1}^{n}x_{ip}\\right)\\right]\\\\\n",
    "& = E\\left[\\frac{1}{n} \\left(\\sum_{i=1}^{n}x_{i1},\\dots,\\sum_{i=1}^{n}x_{ij},\\dotsc,\\sum_{i=1}^{n}x_{ip}\\right)\\right]\\\\\n",
    "& = E\\left[\\frac{1}{n} \\sum_{i=1}^{n} \\left(x_{i1},\\dots,x_{ij},\\dotsc,x_{ip}\\right)\\right]\\\\\n",
    "\\vec{\\mu} & = E\\left[\\frac{1}{n} \\sum_{i=1}^{n} \\textbf{x}_i\\right]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Which means that $\\frac{1}{n} \\sum_{i=1}^{n} \\textbf{x}_i$ denoted by $\\bar{\\textbf{x}}$ is the unbiased estimator for the expected value $\\vec{\\mu}$ of the random vector $\\vec{X}$ and is called **sample mean vector**. if $\\textbf{1}_{1n}$ is a vector of 1's, then $\\bar{\\textbf{x}} = \\frac{1}{n} \\textbf{1}_{1n}^T \\textbf{x}$.\n",
    "\n",
    "#### Covariance matrix\n",
    "\n",
    "Similarly to the univariate case, it is possible to generalize the definition of variance for a random vector of dimension p (in terms of a grammian matrix) as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Sigma_{p \\times p} & = E \\left[ (\\vec{\\textbf{X}}-\\vec{\\mu})(\\vec{\\textbf{X}}-\\vec{\\mu})^T  \\right]\\\\\n",
    "& = E \\left[ \n",
    "    \\left( \\begin{array}{c}\n",
    "    X_1 - \\mu_1 \\\\\n",
    "    \\vdots  \\\\\n",
    "    x_p - \\mu_p \\end{array} \\right)\n",
    "    \\left(X_a - \\mu_1,\\dotsc,X_p-\\mu_p \\right)\n",
    "\\right] \\\\\n",
    "& = E \\left[ \\begin{array}{ccccc}\n",
    "(X_1-\\mu_1)(X_1-\\mu_1) & \\cdots & (X_1-\\mu_1)(X_j-\\mu_j) & \\cdots & (X_1-\\mu_1)(X_p-\\mu_p) \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "(X_i-\\mu_i)(X_1-\\mu_1) & \\cdots & (X_i-\\mu_i)(X_j-\\mu_j) & \\cdots & (X_i-\\mu_i)(X_p-\\mu_p) \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "(X_p-\\mu_p)(X_1-\\mu_1) & \\cdots & (X_p-\\mu_p)(X_j-\\mu_j) & \\cdots & (X_p-\\mu_p)(X_p-\\mu_p) \\end{array} \\right]\\\\\n",
    "& = \\left[ \\begin{array}{ccccc}\n",
    "E[(X_1-\\mu_1)(X_1-\\mu_1)] & \\cdots & E[(X_1-\\mu_1)(X_j-\\mu_j)] & \\cdots & E[(X_1-\\mu_1)(X_p-\\mu_p)] \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "E[(X_i-\\mu_i)(X_1-\\mu_1)] & \\cdots & E[(X_i-\\mu_i)(X_j-\\mu_j)] & \\cdots & E[(X_i-\\mu_i)(X_p-\\mu_p)] \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "E[(X_p-\\mu_p)(X_1-\\mu_1)] & \\cdots & E[(X_p-\\mu_p)(X_j-\\mu_j)] & \\cdots & E[(X_p-\\mu_p)(X_p-\\mu_p)] \n",
    "\\end{array} \\right]\\\\\n",
    "& = \\left[ \\begin{array}{ccccc}\n",
    "Cov(X_1,X_1) & \\cdots & Cov(X_1,X_j) & \\cdots & Cov(X_1,X_p)\\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "Cov(X_i,X_1)& \\cdots & Cov(X_i,X_1) & \\cdots & Cov(X_i,X_p) \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "Cov(X_p,X_1) & \\cdots & Cov(X_p,X_j) & \\cdots & Cov(X_p,X_p) \n",
    "\\end{array} \\right]\\\\\n",
    "\\Sigma_{p \\times p} & = \\left[ \\begin{array}{ccccc}\n",
    "\\sigma_{11} & \\cdots & \\sigma_{1j} & \\cdots & \\sigma_{1p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\sigma_{i1} & \\cdots & \\sigma_{ij} & \\cdots & \\sigma_{ip} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\sigma_{p1} & \\cdots & \\sigma_{pj} & \\cdots & \\sigma_{pp} \n",
    "\\end{array} \\right]\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Although $E\\left[s_{ij} \\right] = E\\left[\\frac{1}{n} \\sum_{k=0}^n (x_{ik}-\\bar{x}_i)(x_{kj}-\\bar{x}_j) \\right] = \\sigma_{ij} - E\\left[(\\bar{x}_i-\\mu_i)(\\bar{x}_j - \\mu_j)\\right] \\neq \\sigma_{ij}$, i.e. $s_{ij}$ it's a biased of $\\sigma_{i,j}$, $s_{ij}$ satisfy the property of being asymptotically unbiased estimator, because $\\lim_{n\\to\\infty} \\sigma_{ij} - E\\left[(\\bar{x}_i-\\mu_i)(\\bar{x}_j - \\mu_j)\\right] = \\sigma_{ij}$ due to the fact $E\\left[(\\bar{x}_i-\\mu_i)(\\bar{x}_j - \\mu_j)\\right] \\rightarrow 0$ (The law of large numbers). Then the covariance matrix could be aproximated asymptotically using sample covariances.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Sigma_{p \\times p} & = \n",
    "\\left[ \\begin{array}{ccccc}\n",
    "\\sigma_{11} & \\cdots & \\sigma_{1j} & \\cdots & \\sigma_{1p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\sigma_{i1} & \\cdots & \\sigma_{ij} & \\cdots & \\sigma_{ip} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\sigma_{p1} & \\cdots & \\sigma_{pj} & \\cdots & \\sigma_{pp} \n",
    "\\end{array} \\right] \n",
    "& \\approx\t \n",
    "\\left[ \\begin{array}{ccccc}\n",
    "s_{11} & \\cdots & s_{1j} & \\cdots & s_{1p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "s_{i1} & \\cdots & s_{ij} & \\cdots & s_{ip} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "s_{p1} & \\cdots & s_{pj} & \\cdots & s_{pp} \n",
    "\\end{array} \\right]\n",
    "& = \\textbf{S}_{p \\times p}\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "#### Correlation matrix (depende measure)\n",
    "\n",
    "The most familiar measure of dependence between two quantities is the Pearson product-moment correlation coefficient, or **Pearson's correlation coefficient**, commonly called simply **the correlation coefficient**. It is obtained by dividing the covariance of the two variables by the product of their standard deviations, this measure could be approximated using the covariance sample.\n",
    "\n",
    "$$\n",
    "\\rho_{X_i,X_j} = \\frac{Cov(X_i,X_j)}{\\sqrt{Cov(X_i,X_i)Cov(X_j,X_j)}} \\approx \\frac{s_{ij}}{\\sqrt{s_{ii} s_{jj}}} = r_{ij} \n",
    "$$\n",
    "\n",
    "It's possible approximate the correlation matrix\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{P}_{p \\times p} & = \n",
    "\\left[ \\begin{array}{ccccc}\n",
    "1 & \\cdots & \\rho_{1j} & \\cdots & \\rho_{1p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\rho_{i1} & \\cdots & 1 & \\cdots & \\rho_{ip} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "\\rho_{p1} & \\cdots & \\rho_{pj} & \\cdots & 1 \n",
    "\\end{array} \\right] \n",
    "& \\approx\t \n",
    "\\left[ \\begin{array}{ccccc}\n",
    "1 & \\cdots & r_{1j} & \\cdots & r_{1p} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "r_{i1} & \\cdots & 1 & \\cdots & r_{ip} \\\\\n",
    "\\vdots  & \\ddots & \\vdots  & \\ddots & \\vdots \\\\\n",
    "r_{p1} & \\cdots & r_{pj} & \\cdots & 1 \n",
    "\\end{array} \\right]\n",
    "& = \\textbf{R}_{p \\times p}\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Example 1.1 - 3 [Computing multivariate statistics with spark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix:\n",
      "[[ 0.68569351 -0.03926846  1.27368233]\n",
      " [-0.03926846  0.18800403 -0.32171275]\n",
      " [ 1.27368233 -0.32171275  3.11317942]]\n",
      "Correlation matrix:\n",
      "[[ 1.         -0.10936925  0.87175416]\n",
      " [-0.10936925  1.         -0.4205161 ]\n",
      " [ 0.87175416 -0.4205161   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "covariance = RowMatrix(irisDF.rdd.map(lambda r: [r[0:3]])).computeCovariance().toArray()\n",
    "correlation = Statistics.corr(irisDF.rdd.map(lambda r: [r[0:3]])) \n",
    "\n",
    "print(\"Covariance matrix:\\n\"+str(covariance))\n",
    "print(\"Correlation matrix:\\n\"+str(correlation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "* \"Multivariate Statistics\", John I. Marden, Department of Statistics, University of Illinois at Urbana-Champaign.\n",
    "* \"Nuevos Métodos de Análisis Multivariante\", Carles M. Cuadras, c C. M. Cuadras, CMC Editions, Manacor 30, 08023 Barcelona, Spain.\n",
    "* \"Applied Multivariate Statistical Analysis\", PennState university, online course STAT 505, (https://onlinecourses.science.psu.edu/stat505/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
